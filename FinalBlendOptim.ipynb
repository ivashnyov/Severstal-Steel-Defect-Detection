{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from factory import *\n",
    "import torch\n",
    "import os \n",
    "import sys\n",
    "from catalyst.dl.callbacks import CriterionCallback, EarlyStoppingCallback, OptimizerCallback, CriterionAggregatorCallback, F1ScoreCallback, AUCCallback\n",
    "from catalyst.dl.runner import SupervisedRunner\n",
    "from pytorch_toolbelt import losses as L\n",
    "from pytorch_toolbelt.inference import tta\n",
    "import collections\n",
    "from pytorch_toolbelt.utils.catalyst import * \n",
    "from metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "from viz_utils import *\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import segmentation_models_pytorch as smp\n",
    "from catalyst.contrib.optimizers import RAdam, Lookahead\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_names = [\n",
    "    'se_resnext50_32x4d_simple',\n",
    "    'se_resnext101_32x4d_simple',\n",
    "    'efficientnet-b5_simple',\n",
    "    'resnext50_32x4d_with_mask_and_boundaries', \n",
    "    'resnext101_32x8d_with_mask_and_boundaries']\n",
    "log_dirs = [\n",
    "    'logs/se_resnext50_32x4d_simple',\n",
    "    'logs/se_resnext101_32x4d_simple',\n",
    "    'logs/efficientnet-b5_simple',\n",
    "    'logs/resnext50_32x4d_with_mask_and_boundaries', \n",
    "    'logs/resnext101_32x8d_with_mask_and_boundaries']\n",
    "encoder_names = [\n",
    "    'se_resnext50_32x4d',\n",
    "    'se_resnext101_32x4d',\n",
    "    'efficientnet-b5',\n",
    "    'resnext50_32x4d', \n",
    "    'resnext101_32x8d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_path = 'data/train.csv'\n",
    "data_folder = \"data/train_images/\"\n",
    "test_data_folder = \"data/test_images/\"\n",
    "val_output_folder = \"data/validation_predictions\"\n",
    "sample_submission_path = 'data/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = return_masks(train_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "images_id = val_df.index.values\n",
    "for exp in experiment_names:\n",
    "    data = np.load(os.path.join(val_output_folder, exp+'.npz.npy'))\n",
    "    data = data[:,:4,...]\n",
    "    data = dict(zip(images_id, data))\n",
    "    print('loaded {}'.format(exp))\n",
    "    all_data.append(data)\n",
    "    del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize optimal threshold and min_size for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_masks = []\n",
    "images_id = []\n",
    "for image_idx in tqdm(range(len(val_df.index.values))):\n",
    "    image_name =  val_df.index.values[image_idx]\n",
    "    labels = val_df.loc[image_name,:][:4]\n",
    "    masks = np.zeros((256, 1600, 4), dtype=np.float32) # float32 is V.Imp\n",
    "    for idx, label in enumerate(labels.values):\n",
    "        if label is not np.nan:\n",
    "            label = label.split(\" \")\n",
    "            positions = map(int, label[0::2])\n",
    "            length = map(int, label[1::2])\n",
    "            mask = np.zeros(256 * 1600, dtype=np.uint8)\n",
    "            for pos, le in zip(positions, length):\n",
    "                mask[pos:(pos + le)] = 1\n",
    "            masks[:, :, idx] = mask.reshape(256, 1600, order='F')\n",
    "    gt_masks.append(masks)\n",
    "    images_id.append(val_df.index.values[image_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_gt_masks = dict(zip(images_id, gt_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_idx = 0\n",
    "thrs = [0.4, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]\n",
    "min_sizes = [400, 450, 500, 550, 600, 650, 700, 750, 800]\n",
    "all_dices = []\n",
    "all_thr = []\n",
    "all_minsizes =[]\n",
    "comb_thr_minsize = itertools.product(thrs, min_sizes)\n",
    "for thr, min_size in tqdm(comb_thr_minsize):\n",
    "    dices_mean = []\n",
    "    for image in images_id:\n",
    "        predictions = torch.nn.Sigmoid()(torch.from_numpy(sum([all_data[exp][image][defect_idx,...] for exp in experiment_names])/len(experiment_names))).numpy()\n",
    "        gt_mask = dict_of_gt_masks[image][...,defect_idx]\n",
    "        predictions_bin = predictions > thr\n",
    "        if predictions_bin.sum() < min_size:\n",
    "            predictions_bin = np.zeros(predictions_bin.shape)\n",
    "        dice_gt_pr = dice(gt_mask,\n",
    "                          predictions_bin,\n",
    "                          empty_score=1.0)\n",
    "        dices_mean.append(dice_gt_pr)\n",
    "    print('thr {}, minsize {}, DICE : {}'.format(thr, min_size, np.mean(dices_mean))) \n",
    "    all_dices.append(np.mean(dices_mean))\n",
    "    all_thr.append(thr)\n",
    "    all_minsizes.append(min_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame({'dices':all_dices, 'thr':all_thr, 'min_size':all_minsizes})\n",
    "scores.sort_values(['dices'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='thr',y='dices',hue='min_size', data=scores, linewidth=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "defect_idx = 1\n",
    "thrs = [0.4, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]\n",
    "min_sizes = [400, 450, 500, 550, 600, 650, 700, 750, 800]\n",
    "all_dices = []\n",
    "all_thr = []\n",
    "all_minsizes =[]\n",
    "comb_thr_minsize = itertools.product(thrs, min_sizes)\n",
    "for thr, min_size in tqdm(comb_thr_minsize):\n",
    "    dices_mean = []\n",
    "    for image in images_id:\n",
    "        predictions = torch.nn.Sigmoid()(torch.from_numpy(sum([all_data[exp][image][defect_idx,...] for exp in experiment_names])/len(experiment_names))).numpy()\n",
    "        gt_mask = dict_of_gt_masks[image][...,defect_idx]\n",
    "        predictions_bin = predictions > thr\n",
    "        if predictions_bin.sum() < min_size:\n",
    "            predictions_bin = np.zeros(predictions_bin.shape)\n",
    "        dice_gt_pr = dice(gt_mask,\n",
    "                          predictions_bin,\n",
    "                          empty_score=1.0)\n",
    "        dices_mean.append(dice_gt_pr)\n",
    "    print('thr {}, minsize {}, DICE : {}'.format(thr, min_size, np.mean(dices_mean))) \n",
    "    all_dices.append(np.mean(dices_mean))\n",
    "    all_thr.append(thr)\n",
    "    all_minsizes.append(min_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame({'dices':all_dices, 'thr':all_thr, 'min_size':all_minsizes})\n",
    "scores.sort_values(['dices'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='thr',y='dices',hue='min_size', data=scores, linewidth=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_idx = 2\n",
    "thrs = [0.4, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]\n",
    "min_sizes = [800, 900, 1000, 1100, 1200]\n",
    "all_dices = []\n",
    "all_thr = []\n",
    "all_minsizes =[]\n",
    "comb_thr_minsize = itertools.product(thrs, min_sizes)\n",
    "for thr, min_size in tqdm(comb_thr_minsize):\n",
    "    dices_mean = []\n",
    "    for image in images_id:\n",
    "        predictions = torch.nn.Sigmoid()(torch.from_numpy(sum([all_data[exp][image][defect_idx,...] for exp in experiment_names])/len(experiment_names))).numpy()\n",
    "        gt_mask = dict_of_gt_masks[image][...,defect_idx]\n",
    "        predictions_bin = predictions > thr\n",
    "        if predictions_bin.sum() < min_size:\n",
    "            predictions_bin = np.zeros(predictions_bin.shape)\n",
    "        dice_gt_pr = dice(gt_mask,\n",
    "                          predictions_bin,\n",
    "                          empty_score=1.0)\n",
    "        dices_mean.append(dice_gt_pr)\n",
    "    print('thr {}, minsize {}, DICE : {}'.format(thr, min_size, np.mean(dices_mean))) \n",
    "    all_dices.append(np.mean(dices_mean))\n",
    "    all_thr.append(thr)\n",
    "    all_minsizes.append(min_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame({'dices':all_dices, 'thr':all_thr, 'min_size':all_minsizes})\n",
    "scores.sort_values(['dices'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='thr',y='dices',hue='min_size', data=scores, linewidth=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_idx = 3\n",
    "thrs = [0.35, 0.4, 0.45,  0.5, 0.55,]\n",
    "min_sizes = [2000, 2050, 2100, 2150, 2200]\n",
    "all_dices = []\n",
    "all_thr = []\n",
    "all_minsizes =[]\n",
    "comb_thr_minsize = itertools.product(thrs, min_sizes)\n",
    "for thr, min_size in tqdm(comb_thr_minsize):\n",
    "    dices_mean = []\n",
    "    for image in images_id:\n",
    "        predictions = torch.nn.Sigmoid()(torch.from_numpy(sum([all_data[exp][image][defect_idx,...] for exp in experiment_names])/len(experiment_names))).numpy()\n",
    "        gt_mask = dict_of_gt_masks[image][...,defect_idx]\n",
    "        predictions_bin = predictions > thr\n",
    "        if predictions_bin.sum() < min_size:\n",
    "            predictions_bin = np.zeros(predictions_bin.shape)\n",
    "        dice_gt_pr = dice(gt_mask,\n",
    "                          predictions_bin,\n",
    "                          empty_score=1.0)\n",
    "        dices_mean.append(dice_gt_pr)\n",
    "    print('thr {}, minsize {}, DICE : {}'.format(thr, min_size, np.mean(dices_mean))) \n",
    "    all_dices.append(np.mean(dices_mean))\n",
    "    all_thr.append(thr)\n",
    "    all_minsizes.append(min_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame({'dices':all_dices, 'thr':all_thr, 'min_size':all_minsizes})\n",
    "scores.sort_values(['dices'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='thr',y='dices',hue='min_size', data=scores, linewidth=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = [0.55, 0.5, 0.55, 0.40]\n",
    "min_size = [650, 500, 1200, 2100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
